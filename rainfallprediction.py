# -*- coding: utf-8 -*-
"""Rainfallprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qhzw00aUv0zzE0zWIFAlZ82slDSj68eT
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.neural_network import MLPClassifier
import pickle

data=pd.read_excel("/content/Weather data.xlsx")

df=data.copy()

df.head()

df.isnull().sum()

x=df.drop("precip_mm",axis=1)
y=df["precip_mm"]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

num_col = x.select_dtypes(include=[int, float])
cat_col=x.select_dtypes(include=[object])

one=OneHotEncoder(handle_unknown='ignore')
sc=StandardScaler()

# Create preprocessing pipelines for numerical and categorical features
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', sc)
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', one)
])

# Create a column transformer to apply different transformations to different columns
ct=ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, num_col.columns.tolist()),
        ('cat', categorical_transformer, cat_col.columns.tolist())
    ])

rfs=RandomForestRegressor()
pipe=Pipeline([('ct',ct),('rfs',rfs)])
pipe.fit(x_train,y_train)

pred=pipe.predict(x_test)

mse=mean_squared_error(y_test,pred)

print(mse)

data=pd.read_excel("/content/Location information.xlsx")

data.head()

with open("rain_model.pkl", "wb") as f:
    pickle.dump(pipe, f)



"""lang chain for genralize model"""

import pickle
import numpy as np
import pandas as pd # Added pandas import

# Load your trained rain model (make sure the file exists)
with open("rain_model.pkl", "rb") as f:
    rain_model = pickle.load(f)

def predict_rain_from_features(features: dict):
    """
    Predict precipitation (mm) from given weather features.
    """

    # Map the 6 input features to the original 19 features of the training data
    # Fill in sensible defaults for features not provided by the user query.
    input_data_ordered = {
        'last_updated_epoch': [1693000000], # Example timestamp
        'temperature_celsius': [float(features.get("temp", 25))],
        'temperature_fahrenheit': [float(features.get("temp", 25)) * 1.8 + 32],
        'wind_mph': [float(features.get("wind", 10))],
        'wind_kph': [float(features.get("wind", 10)) * 1.60934],
        'wind_degree': [180], # Default to a generic direction, e.g., South
        'pressure_mb': [float(features.get("pressure", 1013))],
        'pressure_in': [float(features.get("pressure", 1013)) * 0.02953],
        'precip_in': [0.0], # Default to 0, as we are predicting precip_mm
        'humidity': [float(features.get("humidity", 70))],
        'cloud': [float(features.get("cloud", 50))],
        'feels_like_celsius': [float(features.get("temp", 25))], # Simplified, assume same as temp_celsius
        'feels_like_fahrenheit': [float(features.get("temp", 25)) * 1.8 + 32], # Simplified
        'visibility_km': [float(features.get("visibility", 10))],
        'visibility_miles': [float(features.get("visibility", 10)) * 0.621371],
        'uv_index': [3], # A common average UV index
        'gust_mph': [float(features.get("wind", 10))], # Default gust to wind speed
        'gust_kph': [float(features.get("wind", 10)) * 1.60934], # Default gust to wind speed
        'wind_direction': ['W'] # Default to a common wind direction
    }

    # Create a DataFrame with the correct column order expected by the ColumnTransformer
    # The order of columns must match num_col.columns.tolist() + cat_col.columns.tolist()
    # (from original training setup in earlier cells)
    X_input_df = pd.DataFrame(input_data_ordered)

    # Prediction using the loaded pipeline (which contains the ColumnTransformer and Regressor)
    predicted_precip_mm = rain_model.predict(X_input_df)[0]

    return {
        "predicted_precip_mm": float(predicted_precip_mm),
        "features_used": features
    }

def run_rain_tool(user_query: str):
    """
    1) Extract features via Groq LLM (same as before)
    2) Call predict_rain_from_features(features) (user's ML wrapper)
    3) Decide whether to answer in 'haaan/nahi + probability' or 'predicted_precip_mm'
       based on user's question intent (Hindi/English keywords).
    4) Return a dict with chosen fields (and always include features_used).
    """

    prompt = f"""
User asked: "{user_query}"
Extract the following fields:
temp, humidity, pressure, cloud, wind, visibility, city, predicted_precip_mm (if mentioned).
If missing, assume reasonable defaults.
Return PURE JSON ONLY.
"""
    extracted_text = llm_extractor.invoke(prompt).content

    # JSON extraction (same helper)
    def extract_json(text):
        try:
            return json.loads(text)
        except:
            pass
        m = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if m:
            try:
                return json.loads(m.group(0))
            except:
                pass
        try:
            return json.loads(text.replace("'", '"'))
        except:
            pass
        raise ValueError("Cannot parse JSON from: " + text)

    try:
        features = extract_json(extracted_text)
    except Exception:
        features = {
            "temp": 25,
            "humidity": 70,
            "pressure": 1013,
            "cloud": 50,
            "wind": 10,
            "visibility": 10,
            "city": None
        }

    # Ensure defaults exist
    defaults = {"temp": 25, "humidity": 70, "pressure": 1013, "cloud": 50, "wind": 10, "visibility": 10}
    for k, v in defaults.items():
        if k not in features or features[k] is None:
            features[k] = v

    # --- If user explicitly provided predicted_precip_mm, use it directly ---
    if "predicted_precip_mm" in features:
        precip_mm = float(features["predicted_precip_mm"])
        # convert mm -> probability and label
        mm_to_prob_scale = 5.0   # tweak: 5.0 means 5 mm => 100% probability
        probability = min(1.0, precip_mm / mm_to_prob_scale)
        rain_label = "haan" if precip_mm > 0.1 else "nahi"
        result = {
            "predicted_precip_mm": round(precip_mm, 4),
            "probability": round(probability, 3),
            "rain": rain_label,
            "features_used": features
        }
        # decide how to present based on user intent below
        model_output = result
    else:
        # Call your ML wrapper which may return either:
        # - {'predicted_precip_mm': value, ...}   OR
        # - {'rain': 'haan'/'nahi', 'probability': value, ...}
        model_output = predict_rain_from_features(features)

        # If model_output is numeric or returns raw mm under other key names, normalize:
        if isinstance(model_output, (int, float)):
            model_output = {"predicted_precip_mm": float(model_output)}
        # If it's a dict but has numeric first value, handle below

        # If model gave predicted_precip_mm, convert to prob+label as helper
        if "predicted_precip_mm" in model_output:
            precip_mm = float(model_output["predicted_precip_mm"])
            mm_to_prob_scale = 5.0
            prob = min(1.0, precip_mm / mm_to_prob_scale)
            model_output.setdefault("probability", round(prob, 3))
            model_output.setdefault("rain", "haan" if precip_mm > 0.1 else "nahi")
        else:
            # If model returned probability but not mm, synthesize a mm estimate (inverse of above)
            if "probability" in model_output and "predicted_precip_mm" not in model_output:
                prob = float(model_output["probability"])
                mm_est = prob * mm_to_prob_scale
                model_output["predicted_precip_mm"] = round(mm_est, 4)
            # Ensure rain label exists
            if "rain" not in model_output and "probability" in model_output:
                model_output["rain"] = "haan" if float(model_output["probability"]) >= 0.5 else "nahi"

        # always include features_used
        model_output["features_used"] = features

    # ------------------------
    # Intent detection (what user asked for)
    # ------------------------
    q = user_query.lower()

    # patterns indicating user wants amount (mm)
    amount_patterns = [
        r"\bmm\b", r"millimeter", r"kitni\s+barish", r"kitna\s+barish",
        r"kitni\s*mm", r"how much", r"how many mm", r"precip", r"predicted_precip_mm"
    ]
    # patterns indicating user wants yes/no about rain
    yesno_patterns = [
        r"\bkya\b", r"\bbarish\b", r"\bring\b", r"\bhogi\b", r"\bho(ga|gi)\b", r"\brain\b", r"\bwill it rain\b"
    ]

    wants_amount = any(re.search(p, q) for p in amount_patterns)
    wants_yesno = any(re.search(p, q) for p in yesno_patterns)

    # If both or none detected, prefer yes/no by default for simple queries,
    # but if predicted_precip_mm is substantial, include both.
    response = {}

    if wants_amount and not wants_yesno:
        # user explicitly asked for amount -> return mm (and also probability)
        response = {
            "predicted_precip_mm": model_output.get("predicted_precip_mm"),
            "probability": model_output.get("probability"),
            "features_used": model_output.get("features_used")
        }
    elif wants_yesno and not wants_amount:
        # user asked yes/no -> return haan/nahi + probability
        response = {
            "rain": model_output.get("rain"),
            "probability": model_output.get("probability"),
            "features_used": model_output.get("features_used")
        }
    else:
        # ambiguous or neither -> return both but prioritize clarity
        response = {
            "rain": model_output.get("rain"),
            "probability": model_output.get("probability"),
            "predicted_precip_mm": model_output.get("predicted_precip_mm"),
            "features_used": model_output.get("features_used")
        }

    return response

